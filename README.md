# üõ°Ô∏è DGX RedTeam Suites (H200 Edition)

> **Infrastructure de Pentest Offensif & Agent Autonome IA sur NVIDIA DGX H200.**

Ce d√©p√¥t centralise les configurations Docker optimis√©es pour d√©ployer deux environnements de hacking distincts sur une infrastructure DGX :
1.  ü§ñ **AI-AGENT Edition :** Environnement "Cerveau" avec LLM (Ollama/Qwen), GPU activ√© et Scripts Python d'automatisation.
2.  ‚öîÔ∏è **PURE ARSENAL Edition :** Environnement "Muscle" sous Debian 12, ultra-l√©ger, contenant uniquement l'arsenal offensif.

---

## üìã Architecture & Comparatif

| Caract√©ristique | ü§ñ **AI-AGENT Edition** | ‚öîÔ∏è **PURE ARSENAL Edition** |
| :--- | :--- | :--- |
| **Cas d'usage** | **Agent Autonome**, RAG, Tool Calling, Scripting IA | **Pentest Manuel**, Audit Infra/Web, Red Team |
| **Fichier Docker** | `Dockerfile.agent` | `Dockerfile.pure` |
| **Base OS** | `ollama/ollama:latest` (Ubuntu + CUDA) | `debian:bookworm` (Debian 12 Stable) |
| **Moteur IA** | **Ollama** (Pr√©-install√© & Configur√©) | **Aucun** (Syst√®me Clean) |
| **GPU H200** | **100% Utilisation** (Inf√©rence Qwen3-30B) | Disponible (Hashcat/Cracking optionnel) |
| **Taille Image** | Lourde (~10 Go + Mod√®les) | L√©g√®re (~3 Go) |

### üß† Sch√©ma de Fonctionnement

```mermaid
graph TD
    User[Pentester / User] -->|Prompt ou Commande| Docker
    subgraph "NVIDIA DGX H200 Host"
        Docker[Conteneur Docker]
        GPU[NVIDIA H200 GPU]
        
        subgraph "AI-AGENT Edition"
            Ollama[Svr Ollama]
            Agent[Script Python]
            Tools1[Nmap/Nuclei]
            Ollama <-->|Inference| GPU
            Agent <-->|Tool Calling| Tools1
            Agent <-->|D√©cision JSON| Ollama
        end

        subgraph "PURE ARSENAL Edition"
            Term[Bash Terminal]
            Tools2[Nmap/Nuclei/NetExec]
            Term --> Tools2
        end
    end

üöÄ Pr√©-requis (H√¥te DGX)
Avant de commencer, assurez-vous que les drivers NVIDIA sont op√©rationnels sur l'h√¥te :

Bash

# 1. V√©rifier la d√©tection du H200
nvidia-smi

# 2. V√©rifier que Docker acc√®de au GPU
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi
1Ô∏è‚É£ Utilisation : L'√âdition "AI-AGENT"
Cette version est con√ßue pour l'automatisation intelligente via web_agent.py et le mod√®le Qwen3-Coder.

üèóÔ∏è Build
Assurez-vous que le fichier Dockerfile.agent est √† la racine.

Bash

# Construction de l'image
docker build -f Dockerfile.agent -t pentestia:agent .
‚ö° Run (Lancement)
Nous lan√ßons le conteneur en arri√®re-plan (-d) avec un volume persistant pour les mod√®les Ollama (pour √©viter de ret√©l√©charger 20Go √† chaque fois).

Bash

docker run -d \
  --name pentest-agent \
  --gpus=all \
  --network host \
  --restart unless-stopped \
  -v "$(pwd):/app" \
  -v ollama_storage:/root/.ollama \
  pentestia:agent
üß† Configuration Initiale (Premier Lancement)
Une fois le conteneur d√©marr√©, installez le "Cerveau" :

Bash

# 1. Entrer dans le conteneur
docker exec -it pentest-agent bash

# 2. T√©l√©charger le mod√®le optimis√© H200
ollama pull qwen3-coder:30b

# 3. Lancer l'Agent Autonome
python3 web_agent.py
2Ô∏è‚É£ Utilisation : L'√âdition "PURE ARSENAL"
Cette version est con√ßue pour les tests d'intrusion manuels, sans la surcharge de l'IA.

üèóÔ∏è Build
Assurez-vous que le fichier Dockerfile.pure est √† la racine.

Bash

# Construction de l'image
docker build -f Dockerfile.pure -t pentestia:pure .
‚ö° Run (Lancement)
Acc√®s direct au terminal Debian avec tous les outils pr√©-charg√©s.

Bash

docker run -it \
  --name pentest-pure \
  --network host \
  -v "$(pwd):/app" \
  pentestia:pure
üß∞ Liste des Outils Inclus
Les deux images contiennent l'int√©gralit√© de cet arsenal :

üåê Web Recon & Analysis
ProjectDiscovery Stack : nuclei, httpx, subfinder, katana, naabu, dnsx, notify.

Tomnomnom Suite : gf (avec patterns), qsreplace, waybackurls.

Essential : gau, hakrawler, dalfox, gobuster, amass (v4), sqlmap, arjun, dirsearch, uro, tldextract.

Manual Tools : Findomain, Corsy.

üíÄ Infra & Active Directory
NetExec (nxc) : Audit AD & Network (remplace CrackMapExec).

Impacket / Certipy / BloodHound : Attaque Active Directory compl√®te.

Exploitation : Metasploit Framework, Searchsploit.

Man-in-the-Middle : Responder, Mitm6.

Pivot : Ligolo-ng, Chisel, Proxychains4.

Enumeration : Kerbrute, Evil-WinRM.

ü§ñ IA & Scripting (Agent Edition Uniquement)
Ollama Client (API locale)

ChromaDB (M√©moire Vectorielle / RAG)

Pydantic (Validation stricte des sorties IA)

ReportLab / FPDF2 (G√©n√©ration PDF)

Asyncio / Loguru (Haute performance Python)

‚ùì Troubleshooting
Erreur : externally-managed-environment (Python)

C'est normal sur Debian 12 / Ubuntu 24.04. Solution : N'utilisez pas pip install en root. Nos outils sont install√©s via pipx (isol√©s) et vos scripts Python doivent utiliser l'environnement virtuel pr√©-configur√© : /opt/venv/bin/python.

Erreur : Ollama connection refused

Attendez 5 √† 10 secondes apr√®s le d√©marrage du conteneur pentest-agent. L'initialisation du serveur GPU prend un court instant. V√©rifiez avec docker logs pentest-agent.

Performances :

Sur un DGX H200, privil√©giez toujours des mod√®les quantifi√©s larges (ex: qwen3-coder:30b ou llama3:70b). Les mod√®les 7B sous-utiliseraient massivement votre mat√©riel.
